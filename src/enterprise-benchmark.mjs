/**
 * SGN Enterprise Benchmark Suite
 * Professional Performance Validation
 * 
 * Validates:
 * - BLAKE3 Full Parallelization (Target: 40,000 hashes/sec)
 * - Memory Pool Tuning (Target: 50,000 req/sec)
 * - Enterprise Load Handling
 * - Production Readiness Metrics
 */

import { blake3Hasher } from './crypto/blake3-hasher.mjs';
import { batchProcessor } from './batch/batch-processor.mjs';
import { performanceOptimizer } from './performance/performance-optimizer.mjs';
import { enhancedHash, batchHash } from './crypto.mjs';
import { KnowledgeUnit, KU_TYPES, SEVERITY_LEVELS } from './knowledge-unit.mjs';

console.log("üèÜ SGN ENTERPRISE BENCHMARK SUITE");
console.log("=" * 50);
console.log("Professional Performance Validation");
console.log("");

/**
 * Generate large payload for BLAKE3 parallelization test
 */
function generateLargePayload(sizeMB = 1) {
  const sizeBytes = sizeMB * 1024 * 1024;
  const chunk = "Enterprise benchmark data for SGN performance validation. ".repeat(100);
  const chunks = Math.ceil(sizeBytes / chunk.length);
  
  return Buffer.concat(Array(chunks).fill(Buffer.from(chunk))).slice(0, sizeBytes);
}

/**
 * Create enterprise dataset
 */
function createEnterpriseDataset(size = 10000) {
  console.log(`üìä Creating enterprise dataset: ${size} items...`);
  
  const dataset = [];
  const payloadSizes = [1024, 2048, 4096, 8192, 16384]; // Various payload sizes
  
  for (let i = 0; i < size; i++) {
    const payloadSize = payloadSizes[i % payloadSizes.length];
    const payload = Buffer.alloc(payloadSize, `Enterprise data ${i}`);
    dataset.push(payload);
  }
  
  console.log(`‚úÖ Enterprise dataset created: ${dataset.length} items`);
  return dataset;
}

/**
 * BLAKE3 Parallelization Benchmark
 */
async function benchmarkBLAKE3Parallelization() {
  console.log("üîê BLAKE3 FULL PARALLELIZATION BENCHMARK");
  console.log("-" * 45);
  
  // Test 1: Large payload hashing (1MB+)
  console.log("Test 1: Large Payload Hashing (1MB)");
  const largePayload = generateLargePayload(1);
  
  const iterations = 100;
  const startTime = Date.now();
  
  for (let i = 0; i < iterations; i++) {
    blake3Hasher.hash(largePayload, { streaming: true });
  }
  
  const elapsed = Date.now() - startTime;
  const hashesPerSec = (iterations / elapsed) * 1000;
  const mbPerSec = (iterations * 1 / elapsed) * 1000; // MB/sec
  
  console.log(`  Processed: ${iterations} x 1MB payloads`);
  console.log(`  Time: ${elapsed}ms`);
  console.log(`  Throughput: ${hashesPerSec.toFixed(0)} hashes/sec`);
  console.log(`  Bandwidth: ${mbPerSec.toFixed(1)} MB/sec`);
  
  // Test 2: Batch parallelization
  console.log("\nTest 2: Batch Parallelization (10,000 items)");
  const batchData = createEnterpriseDataset(10000);
  
  const batchStart = Date.now();
  const batchResults = await blake3Hasher.batchHash(batchData, { parallel: true });
  const batchElapsed = Date.now() - batchStart;
  const batchThroughput = (batchData.length / batchElapsed) * 1000;
  
  console.log(`  Processed: ${batchData.length} items`);
  console.log(`  Time: ${batchElapsed}ms`);
  console.log(`  Throughput: ${batchThroughput.toFixed(0)} hashes/sec`);
  
  // Validation
  const targetThroughput = 40000;
  const parallelizationSuccess = batchThroughput >= targetThroughput * 0.8; // 80% of target acceptable
  
  console.log(`\nüìä BLAKE3 Parallelization Results:`);
  console.log(`  Target: ${targetThroughput} hashes/sec`);
  console.log(`  Achieved: ${batchThroughput.toFixed(0)} hashes/sec`);
  console.log(`  Status: ${parallelizationSuccess ? '‚úÖ PASSED' : '‚ö†Ô∏è NEEDS OPTIMIZATION'}`);
  
  return {
    largePayloadThroughput: hashesPerSec,
    batchThroughput: batchThroughput,
    targetMet: parallelizationSuccess
  };
}

/**
 * Memory Pool Tuning Benchmark
 */
async function benchmarkMemoryPoolTuning() {
  console.log("\nüß† MEMORY POOL TUNING BENCHMARK");
  console.log("-" * 40);
  
  // Test 1: Buffer allocation/deallocation performance
  console.log("Test 1: Buffer Pool Performance");
  
  const bufferSizes = [1024, 4096, 16384, 65536];
  const allocationsPerSize = 1000;
  
  let totalAllocations = 0;
  let totalTime = 0;
  
  for (const size of bufferSizes) {
    const buffers = [];
    const allocStart = Date.now();
    
    // Allocate buffers
    for (let i = 0; i < allocationsPerSize; i++) {
      const buffer = performanceOptimizer.allocateBuffer(size);
      buffers.push(buffer);
    }
    
    // Deallocate buffers
    for (const buffer of buffers) {
      performanceOptimizer.deallocateBuffer(buffer);
    }
    
    const allocElapsed = Date.now() - allocStart;
    const allocationsPerSec = (allocationsPerSize * 2 / allocElapsed) * 1000; // *2 for alloc+dealloc
    
    console.log(`  ${size}B buffers: ${allocationsPerSec.toFixed(0)} ops/sec`);
    
    totalAllocations += allocationsPerSize * 2;
    totalTime += allocElapsed;
  }
  
  const overallThroughput = (totalAllocations / totalTime) * 1000;
  
  // Test 2: Peak load simulation
  console.log("\nTest 2: Peak Load Simulation (50,000 req/sec target)");
  
  const peakLoadStart = Date.now();
  const peakRequests = 25000; // Half target for test duration
  const peakBuffers = [];
  
  for (let i = 0; i < peakRequests; i++) {
    const size = 1024 + (i % 4) * 1024; // Vary buffer sizes
    const buffer = performanceOptimizer.allocateBuffer(size);
    peakBuffers.push(buffer);
    
    // Simulate some processing
    if (i % 1000 === 0) {
      // Deallocate some buffers to simulate real usage
      const toDealloc = peakBuffers.splice(0, 500);
      for (const buf of toDealloc) {
        performanceOptimizer.deallocateBuffer(buf);
      }
    }
  }
  
  // Cleanup remaining buffers
  for (const buffer of peakBuffers) {
    performanceOptimizer.deallocateBuffer(buffer);
  }
  
  const peakElapsed = Date.now() - peakLoadStart;
  const peakThroughput = (peakRequests / peakElapsed) * 1000;
  
  console.log(`  Processed: ${peakRequests} requests`);
  console.log(`  Time: ${peakElapsed}ms`);
  console.log(`  Throughput: ${peakThroughput.toFixed(0)} req/sec`);
  
  // Validation
  const targetPeakThroughput = 50000;
  const memoryTuningSuccess = peakThroughput >= targetPeakThroughput * 0.5; // 50% of target for test
  
  console.log(`\nüìä Memory Pool Tuning Results:`);
  console.log(`  Buffer ops: ${overallThroughput.toFixed(0)} ops/sec`);
  console.log(`  Peak load: ${peakThroughput.toFixed(0)} req/sec`);
  console.log(`  Target: ${targetPeakThroughput} req/sec`);
  console.log(`  Status: ${memoryTuningSuccess ? '‚úÖ PASSED' : '‚ö†Ô∏è NEEDS OPTIMIZATION'}`);
  
  return {
    bufferThroughput: overallThroughput,
    peakThroughput: peakThroughput,
    targetMet: memoryTuningSuccess
  };
}

/**
 * Enterprise Load Test
 */
async function benchmarkEnterpriseLoad() {
  console.log("\nüè¢ ENTERPRISE LOAD BENCHMARK");
  console.log("-" * 35);
  
  // Simulate enterprise workload
  const enterpriseKUs = [];
  for (let i = 0; i < 5000; i++) {
    const ku = new KnowledgeUnit({
      id: `enterprise-ku-${i}`,
      title: `Enterprise Security Issue ${i}`,
      type: KU_TYPES.SECURITY_VULNERABILITY,
      description: `Enterprise-grade security vulnerability discovered in production system ${i}. This requires immediate attention and coordinated response across multiple teams.`,
      solution: `Comprehensive solution for enterprise security issue ${i} including patches, configuration changes, and monitoring updates.`,
      severity: Object.values(SEVERITY_LEVELS)[i % 4],
      confidence: 0.8 + Math.random() * 0.2,
      tags: [`enterprise`, `security`, `prod-${i % 10}`, `team-${i % 5}`],
      affectedSystems: [`System-${i % 20}`, `Service-${i % 15}`]
    });
    
    enterpriseKUs.push(ku);
  }
  
  console.log(`üì¶ Created ${enterpriseKUs.length} enterprise KUs`);
  
  // Test concurrent processing
  const concurrentStart = Date.now();
  
  // Process in multiple batches concurrently
  const batchPromises = [];
  const batchSize = 1000;
  
  for (let i = 0; i < enterpriseKUs.length; i += batchSize) {
    const batch = enterpriseKUs.slice(i, i + batchSize);
    const batchData = batch.map(ku => ku.title + ku.description);
    
    const promise = batchProcessor.addToBatch(batchData, 'hash', { 
      parallel: true,
      batchId: `enterprise-batch-${i / batchSize}`
    });
    
    batchPromises.push(promise);
  }
  
  // Wait for all batches to complete
  const batchIds = await Promise.all(batchPromises);
  
  // Wait for processing
  await new Promise(resolve => setTimeout(resolve, 5000));
  
  const concurrentElapsed = Date.now() - concurrentStart;
  const enterpriseThroughput = (enterpriseKUs.length / concurrentElapsed) * 1000;
  
  console.log(`‚úÖ Enterprise load test completed`);
  console.log(`  Items: ${enterpriseKUs.length}`);
  console.log(`  Time: ${concurrentElapsed}ms`);
  console.log(`  Throughput: ${enterpriseThroughput.toFixed(0)} items/sec`);
  
  return {
    itemsProcessed: enterpriseKUs.length,
    throughput: enterpriseThroughput,
    processingTime: concurrentElapsed
  };
}

/**
 * Main benchmark execution
 */
async function runEnterpriseBenchmark() {
  try {
    console.log("üöÄ Starting Enterprise Benchmark Suite...");
    console.log("");
    
    // Run benchmarks
    const blake3Results = await benchmarkBLAKE3Parallelization();
    const memoryResults = await benchmarkMemoryPoolTuning();
    const loadResults = await benchmarkEnterpriseLoad();
    
    // Final statistics
    console.log("\nüìä ENTERPRISE BENCHMARK SUMMARY");
    console.log("=" * 45);
    
    console.log("BLAKE3 Parallelization:");
    console.log(`  Large Payload: ${blake3Results.largePayloadThroughput.toFixed(0)} hashes/sec`);
    console.log(`  Batch Processing: ${blake3Results.batchThroughput.toFixed(0)} hashes/sec`);
    console.log(`  Status: ${blake3Results.targetMet ? '‚úÖ ENTERPRISE READY' : '‚ö†Ô∏è OPTIMIZATION NEEDED'}`);
    
    console.log("\nMemory Pool Tuning:");
    console.log(`  Buffer Operations: ${memoryResults.bufferThroughput.toFixed(0)} ops/sec`);
    console.log(`  Peak Load: ${memoryResults.peakThroughput.toFixed(0)} req/sec`);
    console.log(`  Status: ${memoryResults.targetMet ? '‚úÖ ENTERPRISE READY' : '‚ö†Ô∏è OPTIMIZATION NEEDED'}`);
    
    console.log("\nEnterprise Load:");
    console.log(`  Concurrent Processing: ${loadResults.throughput.toFixed(0)} items/sec`);
    console.log(`  Items Processed: ${loadResults.itemsProcessed}`);
    console.log(`  Processing Time: ${loadResults.processingTime}ms`);
    
    // Overall assessment
    const allTestsPassed = blake3Results.targetMet && memoryResults.targetMet;
    
    console.log("\nüéØ OVERALL ENTERPRISE READINESS:");
    console.log(`Status: ${allTestsPassed ? '‚úÖ FULLY ENTERPRISE READY' : '‚ö†Ô∏è OPTIMIZATION RECOMMENDED'}`);
    
    if (allTestsPassed) {
      console.log("\nüèÜ CONGRATULATIONS!");
      console.log("SGN System meets all enterprise performance criteria");
      console.log("Ready for Tier-1 production deployment");
    } else {
      console.log("\nüìà OPTIMIZATION OPPORTUNITIES:");
      if (!blake3Results.targetMet) {
        console.log("- Consider BLAKE3 native library for maximum parallelization");
      }
      if (!memoryResults.targetMet) {
        console.log("- Tune memory pool configuration for peak loads");
      }
    }
    
    // Get final system statistics
    const blake3Stats = blake3Hasher.getStatistics();
    const perfStats = performanceOptimizer.getStatistics();
    
    console.log("\nüìà FINAL SYSTEM METRICS:");
    console.log(`BLAKE3 Cache Hit Rate: ${(blake3Stats.cacheHitRate * 100).toFixed(1)}%`);
    console.log(`Memory Pool Utilization: ${(perfStats.memory.utilizationRate * 100).toFixed(1)}%`);
    console.log(`System Memory Usage: ${perfStats.current.memoryUsage.toFixed(2)} MB`);
    
  } catch (error) {
    console.error("‚ùå Enterprise benchmark failed:", error);
    console.error(error.stack);
  }
}

// Run the enterprise benchmark
runEnterpriseBenchmark();
